import os
import torch
import argparse
import matplotlib.pyplot as plt
import numpy as np
from model.unet import UNet
from lowlight_dataset import NightCitySegmentationDataset, PairedTransform


# ===============================
# üé® H√†m t√¥ m√†u cho mask d·ª± ƒëo√°n
# ===============================
def colorize_mask(mask, num_classes):
    """T·∫°o ·∫£nh m√†u tr·ª±c quan cho mask segmentation."""
    np.random.seed(42)
    colors = np.random.randint(0, 255, size=(num_classes, 3), dtype=np.uint8)
    color_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)
    for c in range(num_classes):
        color_mask[mask == c] = colors[c]
    return color_mask


# ===============================
# üñºÔ∏è H√†m visualize d·ª± ƒëo√°n
# ===============================
@torch.no_grad()
def visualize_predictions(checkpoint_path, imgdir, maskdir=None,
                          num_classes=20, size=224, num_images=3,
                          device=None, output_dir="outputs"):
    """
    Hi·ªÉn th·ªã v√† l∆∞u ·∫£nh: ·∫£nh g·ªëc | ground truth | d·ª± ƒëo√°n segmentation.

    Args:
        checkpoint_path (str): ƒê∆∞·ªùng d·∫´n model .pth
        imgdir (str): Th∆∞ m·ª•c ·∫£nh test
        maskdir (str): Th∆∞ m·ª•c ch·ª©a mask ground truth (c√≥ th·ªÉ None)
        num_classes (int): S·ªë l·ªõp segmentation
        size (int): K√≠ch th∆∞·ªõc resize ·∫£nh
        num_images (int): S·ªë ·∫£nh hi·ªÉn th·ªã
        output_dir (str): Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
    """
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"üîπ Loading model from: {checkpoint_path}")
    model = UNet(n_channels=3, n_classes=num_classes).to(device)

    # Load tr·ªçng s·ªë model
    checkpoint = torch.load(checkpoint_path, map_location=device)
    if "model" in checkpoint:
        model.load_state_dict(checkpoint["model"])
    else:
        model.load_state_dict(checkpoint)
    model.eval()

    # Dataset: c√≥ ho·∫∑c kh√¥ng c√≥ mask ground truth
    test_transform = PairedTransform(size=(size, size))
    dataset = NightCitySegmentationDataset(
        img_dir=imgdir,
        mask_dir=maskdir,
        transform=test_transform
    )
    print(f"üîπ Loaded {len(dataset)} test images for visualization")

    os.makedirs(output_dir, exist_ok=True)
    indices = np.random.choice(len(dataset), min(num_images, len(dataset)), replace=False)

    for idx, i in enumerate(indices):
        image, mask_gt = dataset[i]
        image = image.unsqueeze(0).to(device)

        # D·ª± ƒëo√°n segmentation
        pred_logits = model(image)
        pred_mask = torch.argmax(pred_logits, dim=1).squeeze(0).cpu().numpy()

        # Chu·∫©n b·ªã hi·ªÉn th·ªã
        img_vis = image.squeeze(0).permute(1, 2, 0).cpu().numpy()
        img_vis = np.clip(img_vis, 0, 1)
        pred_vis = colorize_mask(pred_mask, num_classes)

        # N·∫øu c√≥ ground truth, t√¥ m√†u cho n√≥
        if mask_gt is not None and torch.is_tensor(mask_gt):
            gt_mask = mask_gt.squeeze(0).cpu().numpy().astype(np.uint8)
            gt_vis = colorize_mask(gt_mask, num_classes)
        else:
            gt_vis = None

        # ========== Hi·ªÉn th·ªã ==========
        plt.figure(figsize=(12, 4))

        # ·∫¢nh g·ªëc
        plt.subplot(1, 3 if gt_vis is not None else 2, 1)
        plt.imshow(img_vis)
        plt.title("·∫¢nh g·ªëc")
        plt.axis("off")

        # Ground truth (n·∫øu c√≥)
        if gt_vis is not None:
            plt.subplot(1, 3, 2)
            plt.imshow(gt_vis)
            plt.title("Mask Ground Truth")
            plt.axis("off")

            plt.subplot(1, 3, 3)
            plt.imshow(pred_vis)
            plt.title("Mask D·ª± ƒëo√°n")
            plt.axis("off")
        else:
            plt.subplot(1, 2, 2)
            plt.imshow(pred_vis)
            plt.title("Mask D·ª± ƒëo√°n")
            plt.axis("off")

        plt.tight_layout()

        # L∆∞u ·∫£nh
        save_path = os.path.join(output_dir, f"prediction_{idx+1}.png")
        plt.savefig(save_path)
        plt.show()

        print(f"üíæ Saved visualization: {save_path}")


# ===============================
# üöÄ Ch·∫°y b·∫±ng tham s·ªë d√≤ng l·ªánh
# ===============================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Hi·ªÉn th·ªã k·∫øt qu·∫£ segmentation d·ª± ƒëo√°n.")
    parser.add_argument("--checkpoint", type=str, required=True, help="ƒê∆∞·ªùng d·∫´n file .pth model.")
    parser.add_argument("--imgdir", type=str, required=True, help="Th∆∞ m·ª•c ·∫£nh test.")
    parser.add_argument("--maskdir", type=str, default=None, help="Th∆∞ m·ª•c ch·ª©a mask ground truth (c√≥ th·ªÉ b·ªè tr·ªëng).")
    parser.add_argument("--numclasses", type=int, default=20, help="S·ªë l·ªõp segmentation.")
    parser.add_argument("--size", type=int, default=224, help="K√≠ch th∆∞·ªõc resize ·∫£nh.")
    parser.add_argument("--numimages", type=int, default=3, help="S·ªë ·∫£nh hi·ªÉn th·ªã.")
    parser.add_argument("--outputdir", type=str, default="outputs", help="Th∆∞ m·ª•c l∆∞u ·∫£nh k·∫øt qu·∫£.")

    args = parser.parse_args()

    visualize_predictions(
        checkpoint_path=args.checkpoint,
        imgdir=args.imgdir,
        maskdir=args.maskdir,
        num_classes=args.numclasses,
        size=args.size,
        num_images=args.numimages,
        output_dir=args.outputdir
    )

